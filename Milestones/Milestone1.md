# Project List:

1. DSC520 Project - Being a Dog Owner in NYC
2. DSC540 Project - Crime in Portland Compared to Nationwide
2. DSC550 Case Study - Disney Plus Streaming Data
3. DSC630 Project - Bluetooth Vehicle Travel Sensors
4. DSC640 Project - Airline Safety
5. DSC510 Final Project - Using a web API
6. DSC550 - Classifying Comments using Neural Networks
7. DSC650 - Text Processing
8. DSC680 Project 1 - Detecting Prime Numbers with Machine Learning
9. DSC680 Project 2
10.DSC680 Project 3

# GitHub Portfolio Link:

https://brandonsams.github.io

# ReadMe - Crime in Portland Compared to Nationwide

When I chose my topic for this project, I tried to choose something that:

1. Could be found from a variety of source types
2. Had plenty of numerical data associated with it

For that reason, I decided to just find a bunch of crime-related data and do some cleaning and analysis of that data. I think it worked out relatively well. My skills increased, and now there is not a daunting amount of work ahead of me the next time I want to scrape data from a website or API, for instance. I had used APIs before, but never had scraped any data from a website previously, so I had to start from square one by figuring out the basics of html. That was one of the biggest hurdles with this project.

So getting the data was a big challenge, but once I got my hands on it, it was another challenge figuring what exactly to do with it. I ended up doing some indexing and column renaming to clean some of the dataframes up. I also made sure to convert my data to the proper type before I tried to do something with it. This took some work, but I am finally getting the hang of working with data in dataframes, and that nice. Kinda proud of myself here. 

I like the database content that we dug into during the final week of this course. This showed me that there is an excellent way to save the dataframes, which is to put into a database. I especially like this, because the data can be stored at an offsite location in a secure manner. And I can come back to the data at any time, without having to run the jupyter notebook again.

But with the visualization stage, I found myself running into (what felt like) plenty of trouble when it came to visualizing something from multiple tables. I wasn't sure how to compare the data that I had collected for crime in Portland, OR to the national crime statistics that I had compiled. I get that there is probably a way to summarize the data from the Portland data set (which is much bigger), but I had no idea what would be a good way to do that. So I ended up visualizing other aspects of the data that I had cleaned.

# ReadMe - Airline Safety

"Between 33% and 40% of all people experience some form of anxiety when it comes to flying", according to Stratosjets. While in most cases, this fear is manageable, "between 2.5% and 5% of the population have crippling anxiety, a genuine fear of flying that is classified as a clinical phobia."

With that being said, there is no shortage of one-line quips about how safe flying really is. For example the previous Stratosjets article states,

"There was a 1 in 3.37 billion chance of dying in a commercial airline plane crash between 2012-2016."

"98.6% of crashes do not result in a fatality."

"Of the 140 plane accidents during 2012-2016, only two involved fatalities (1.4%)."

"Commercial plane incidents cause death only once in 20 million flights."
With that said, there is often little explanation as to where statistics like these come from. This blog post will start from data, and show exactly how flying is safer than ever.
